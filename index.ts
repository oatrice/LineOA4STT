import { Elysia } from 'elysia'
import { Client, middleware, validateSignature } from '@line/bot-sdk'
import { createHash } from 'crypto'
import { createClient } from '@supabase/supabase-js'
import { promises as fs } from 'fs'
import * as path from 'path'
import { Readable } from 'stream'
import { SpeechClient, protos } from '@google-cloud/speech'
import { promisify } from 'util'
import { exec } from 'child_process'

const execPromise = promisify(exec)

const AudioEncoding = protos.google.cloud.speech.v1.RecognitionConfig.AudioEncoding

// Helper function to convert a Readable stream to a Buffer
async function streamToBuffer(stream: Readable): Promise<Buffer> {
  return new Promise((resolve, reject) => {
    const chunks: Buffer[] = []
    stream.on('data', (chunk) => chunks.push(chunk))
    stream.on('end', () => resolve(Buffer.concat(chunks)))
    stream.on('error', reject)
  })
}

// Supabase client
const supabase = createClient(
  process.env.SUPABASE_URL || '',
  process.env.SUPABASE_ANON_KEY || ''
)

// Line client
const lineClient = new Client({
  channelAccessToken: process.env.LINE_CHANNEL_ACCESS_TOKEN || ''
})

// Google Cloud Speech-to-Text client
const speechClient = new SpeechClient()

// ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ audio messages
async function handleAudioMessage(event: LineWebhookEvent) {
  try {
    if (!event.message || !event.replyToken || !event.source.userId) {
      console.error('‚ùå Missing required fields for audio processing')
      return
    }

    console.log(`üéµ Processing audio message: ${event.message.id}`)
    
    // 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á job record ‡πÉ‡∏ô Supabase
    const { data: job, error: insertError } = await supabase
      .from('transcription_jobs')
      .insert({
        message_id: event.message.id,
        user_id: event.source.userId,
        reply_token: event.replyToken,
        status: 'PENDING'
      })
      .select()
      .single()

    if (insertError) {
      console.error('‚ùå Failed to create job:', insertError)
      return
    }

    console.log(`‚úÖ Created job ${job.id} for message ${event.message.id}`)

    // 2. ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö user ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    await lineClient.replyMessage(event.replyToken, {
      type: 'text',
      text: 'üéµ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏Ñ‡∏£‡∏±‡∏ö...'
    })

    // 3. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö async (‡πÑ‡∏°‡πà block webhook response)
    processAudioAsync(event.message.id, job.id, event.source.userId, event.timestamp)

  } catch (error) {
    console.error('‚ùå Error handling audio message:', error)
  }
}

// ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö async
async function processAudioAsync(messageId: string, jobId: string, userId: string, timestamp: number) {
  let audioFilePath: string | undefined
  let convertedAudioPath: string | undefined
  try {
    console.log(`üîÑ Processing audio ${messageId} for job ${jobId}`)

    // 1. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å Line
    const contentStream = await lineClient.getMessageContent(messageId)
    const audioBuffer = await streamToBuffer(contentStream)
    
    // ‡∏™‡∏£‡πâ‡∏≤‡∏á directory ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    const tempDir = path.join(process.cwd(), 'temp_audio')
    await fs.mkdir(tempDir, { recursive: true })

    // ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞ path
    audioFilePath = path.join(tempDir, `${messageId}.m4a`) // Line ‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô .m4a
    await fs.writeFile(audioFilePath, audioBuffer)

    console.log(`‚úÖ Audio file downloaded to: ${audioFilePath}`)

    // 2. Convert audio to WAV using ffmpeg
    convertedAudioPath = path.join(tempDir, `${messageId}.wav`)
    try {
      console.log(`üîß Converting ${audioFilePath} to ${convertedAudioPath}...`)
      await execPromise(`ffmpeg -y -i "${audioFilePath}" -acodec pcm_s16le -ar 16000 -ac 1 "${convertedAudioPath}"`)
      console.log(`‚úÖ Audio converted successfully.`)
    } catch (ffmpegError) {
      console.error('‚ùå FFmpeg conversion failed:', ffmpegError)
      await supabase
        .from('transcription_jobs')
        .update({
          status: 'FAILED',
          error_message: 'FFmpeg conversion failed: ' + (ffmpegError instanceof Error ? ffmpegError.message : 'Unknown error'),
        })
        .eq('id', jobId)
      return
    }

    // 3. Read the converted audio file
    const convertedAudioBuffer = await fs.readFile(convertedAudioPath)

    // 4. ‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà Google Cloud Speech-to-Text API
    const audio = {
      content: convertedAudioBuffer.toString('base64'),
    }
    const config = {
      encoding: AudioEncoding.LINEAR16,
      sampleRateHertz: 16000,
      languageCode: 'th-TH',
    }
    const request = {
      audio: audio,
      config: config,
    }

    console.log('üéôÔ∏è Sending audio to Google STT API...')
    const [response] = await speechClient.recognize(request as protos.google.cloud.speech.v1.IRecognizeRequest)
    const transcription = response.results
      ?.map(result => result.alternatives?.[0]?.transcript)
      .join('\n') || ''
    const confidence = response.results?.[0]?.alternatives?.[0]?.confidence || 0

    console.log(`üìù Transcription Result: ${transcription}`)
    console.log(`üìä Confidence: ${confidence}`)

    // 5. ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï job record ‡∏î‡πâ‡∏ß‡∏¢‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå STT
    await supabase
      .from('transcription_jobs')
      .update({
        audio_file_path: audioFilePath, // or convertedAudioPath? Let's stick with original for now.
        status: 'COMPLETED',
        transcript: transcription,
        confidence: confidence,
        provider: 'google-cloud-stt',
        completed_at: new Date().toISOString()
      })
      .eq('id', jobId)

    // ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏´‡πâ user
    let displayName = '‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ' // Default name in case of error
    try {
      const userProfile = await lineClient.getProfile(userId)
      displayName = userProfile.displayName
    } catch (error) {
      console.error(`Failed to get profile for user ${userId}:`, error)
    }

    const messageTime = new Date(timestamp)
    const timeString = messageTime.toLocaleTimeString('th-TH', {
      hour: '2-digit',
      minute: '2-digit',
      hour12: false,
      timeZone: 'Asia/Bangkok',
    })

    await lineClient.pushMessage(userId, {
      type: 'text',
      text: `‚ú® ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö!\n\n‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠ ${timeString}\n‡∏à‡∏≤‡∏Å: ${displayName}\n‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: ${transcription}`,
    })

    console.log(`‚úÖ Completed job ${jobId}`)
    
  } catch (error) {
    console.error('‚ùå Error in async processing:', error)
    
    // Update job ‡∏ß‡πà‡∏≤ failed
    await supabase
      .from('transcription_jobs')
      .update({
        status: 'FAILED',
        error_message: error instanceof Error ? error.message : 'Unknown error'
      })
      .eq('id', jobId)
  } finally {
    // ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à
    if (audioFilePath) {
      try {
        await fs.unlink(audioFilePath)
        console.log(`üóëÔ∏è Deleted temporary audio file: ${audioFilePath}`)
      } catch (cleanupError) {
        console.error('‚ùå Error deleting temporary audio file:', cleanupError)
      }
    }
    if (convertedAudioPath) {
      try {
        await fs.unlink(convertedAudioPath)
        console.log(`üóëÔ∏è Deleted temporary converted file: ${convertedAudioPath}`)
      } catch (cleanupError) {
        console.error('‚ùå Error deleting temporary converted file:', cleanupError)
      }
    }
  }
}

// Type-safe interfaces ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Line webhook payload
interface LineWebhookEvent {
  type: 'message' | 'follow' | 'unfollow' | 'join' | 'leave' | 'postback' | 'beacon'
  timestamp: number
  source: {
    type: 'user' | 'group' | 'room'
    userId?: string
    groupId?: string
    roomId?: string
  }
  replyToken?: string
  message?: {
    id: string
    type: 'text' | 'image' | 'video' | 'audio' | 'file' | 'location' | 'sticker'
    text?: string
    originalContentUrl?: string
    previewImageUrl?: string
    fileName?: string
    fileSize?: number
    duration?: number
  }
  webhookEventId?: string
  deliveryContext?: {
    isRedelivery: boolean
  }
}

interface LineWebhookPayload {
  destination: string
  events: LineWebhookEvent[]
}

// Environment variables (‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ .env ‡πÉ‡∏ô production)
const LINE_CHANNEL_SECRET = process.env.LINE_CHANNEL_SECRET || 'your-line-channel-secret'

// Custom Plugin ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Line Signature Validation
const lineSignatureValidation = new Elysia({ name: 'line-signature' })
  .onParse(async ({ request, set }) => {
    const signature = request.headers.get('x-line-signature')
    
    if (!signature) {
      console.error('‚ö†Ô∏è Missing x-line-signature header')
      set.status = 401
      return { status: 'error', message: 'Unauthorized: Missing signature' }
    }

    const rawBody = await request.text()
    
    const hash = createHash('SHA256')
      .update(rawBody)
      .digest('base64')
    
    const expectedSignature = `sha256=${hash}`
    
    if (signature !== expectedSignature) {
      console.error('‚ö†Ô∏è Invalid Line signature detected')
      console.error('Headers:', Object.fromEntries(request.headers.entries()))
      console.error('Raw Body:', rawBody)
      console.error('Expected Signature:', expectedSignature)
      console.error('Received Signature:', signature)
      set.status = 401
      return { status: 'error', message: 'Unauthorized: Invalid signature' }
    }
    
    console.log('‚úÖ Valid Line signature')
    
    // Return parsed JSON body for Elysia to use
    return JSON.parse(rawBody)
  })

// ‡∏™‡∏£‡πâ‡∏≤‡∏á Elysia App ‡∏û‡∏£‡πâ‡∏≠‡∏° Type-safe configuration
const app = new Elysia()
  .use(lineSignatureValidation)
  .get('/', () => 'Line OA STT Bot is running!')
  .post('/webhook', async ({ body, request, set }) => {
    try {
      // Type-safe parse ‡∏Ç‡∏≠‡∏á webhook payload
      const webhookData = body as LineWebhookPayload
      
      console.log(`üì® Received ${webhookData.events.length} events from ${webhookData.destination}`)
      
      // Process events
      for (const event of webhookData.events) {
        console.log(`üîç Processing event type: ${event.type}`)
        
        if (event.type === 'message' && event.message) {
          switch (event.message.type) {
            case 'text':
              // --- START: ‡πÄ‡∏û‡∏¥‡πà‡∏° Logic ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ---
              if (event.message.text === '‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ' && event.replyToken) {
                await lineClient.replyMessage(event.replyToken, {
                  type: 'text',
                  text: '‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?'
                });
              }
              // --- END: ‡πÄ‡∏û‡∏¥‡πà‡∏° Logic ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ---
              console.log(`üí¨ Text message: ${event.message.text}`)
              break
            case 'audio':
              console.log(`üéµ Audio message: ${event.message.id}`)
              await handleAudioMessage(event)
              break
            case 'image':
              console.log(`üñºÔ∏è Image message: ${event.message.id}`)
              break
            default:
              console.log(`üìé Other message type: ${event.message.type}`)
              if (event.replyToken) {
                await lineClient.replyMessage(event.replyToken, {
                  type: 'text',
                  text: '‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ö‡∏≠‡∏ó‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ üôè'
                })
              }
              break
          }
        }
        
        // TODO: Add other event types (follow, unfollow, etc.)
      }
      
      // ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö Line platform ‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö webhook ‡πÅ‡∏•‡πâ‡∏ß
      set.status = 200
      return { status: 'ok', message: 'Webhook processed successfully' }
      
    } catch (error) {
      console.error('‚ùå Webhook error:', error)
      set.status = 500
      return { status: 'error', message: 'Internal server error' }
    }
  })

// Export ‡πÄ‡∏õ‡πá‡∏ô fetch handler ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö runtime ‡∏ï‡πà‡∏≤‡∏á‡πÜ (Bun, Deno, Cloudflare Workers)
export default app.handle

// ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô local development ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ Bun ‡πÑ‡∏î‡πâ:
// bun --watch index.ts